#!/usr/bin/env python3
"""
Integration test for challenge video endpoints
"""
import asyncio
import json
import sys
import os
from unittest.mock import Mock, AsyncMock

# Add the backend directory to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from api.challenge_video_endpoints import (
    initiate_multi_video_upload,
    upload_video_chunk_for_merge,
    complete_merge_video_upload,
    get_merge_session_status
)
from services.upload_service import ChunkedUploadService
from models import UploadSession, UploadStatus
from datetime import datetime
import uuid

async def test_initiate_multi_video_upload_logic():
    """Test the multi-video upload initiation logic"""
    print("Testing multi-video upload initiation logic...")
    
    # Mock the upload service
    mock_upload_service = Mock(spec=ChunkedUploadService)
    
    # Create mock sessions
    mock_sessions = []
    for i in range(3):
        session = UploadSession(
            session_id=str(uuid.uuid4()),
            user_id="test-user",
            filename=f"video{i+1}.mp4",
            file_size=5000000,
            chunk_size=1048576,
            total_chunks=5,
            mime_type="video/mp4",
            metadata={
                "merge_session_id": "test-merge-session",
                "video_index": i,
                "video_count": 3,
                "is_merge_video": True
            }
        )
        mock_sessions.append(session)
    
    # Mock the initiate_upload method
    mock_upload_service.initiate_upload = AsyncMock(side_effect=mock_sessions)
    
    # Test data validation
    valid_data = {
        "video_count": 3,
        "filenames": ["video1.mp4", "video2.mp4", "video3.mp4"],
        "file_sizes": [5000000, 4500000, 5500000],
        "durations": [15.0, 12.5, 18.2],
        "mime_types": ["video/mp4", "video/mp4", "video/mp4"]
    }
    
    # Validate video count
    if valid_data["video_count"] != 3:
        print("‚úó Video count validation failed")
        return False
    
    # Validate array lengths
    arrays = [valid_data["filenames"], valid_data["file_sizes"], 
              valid_data["durations"], valid_data["mime_types"]]
    if not all(len(arr) == valid_data["video_count"] for arr in arrays):
        print("‚úó Array length validation failed")
        return False
    
    # Validate file sizes
    from config import settings
    for i, size in enumerate(valid_data["file_sizes"]):
        if size <= 0 or size > settings.MAX_FILE_SIZE:
            print(f"‚úó File size validation failed for video {i+1}")
            return False
    
    # Validate durations
    for i, duration in enumerate(valid_data["durations"]):
        if duration <= 0 or duration > settings.MAX_VIDEO_DURATION_SECONDS:
            print(f"‚úó Duration validation failed for video {i+1}")
            return False
    
    # Validate MIME types
    for i, mime_type in enumerate(valid_data["mime_types"]):
        if mime_type not in settings.ALLOWED_VIDEO_TYPES:
            print(f"‚úó MIME type validation failed for video {i+1}")
            return False
    
    print("‚úì All validation checks passed")
    
    # Test merge session ID generation
    merge_session_id = str(uuid.uuid4())
    if not merge_session_id:
        print("‚úó Merge session ID generation failed")
        return False
    
    print("‚úì Merge session ID generation working")
    
    # Test estimated merge time calculation
    total_duration = sum(valid_data["durations"])
    total_size = sum(valid_data["file_sizes"])
    
    base_merge_time = 10.0
    duration_factor = total_duration * 0.5
    size_factor = total_size / (1024 * 1024) * 0.1
    estimated_merge_time = base_merge_time + duration_factor + size_factor
    
    if estimated_merge_time <= 0:
        print("‚úó Merge time estimation failed")
        return False
    
    print(f"‚úì Estimated merge time: {estimated_merge_time:.2f} seconds")
    
    return True

async def test_upload_session_metadata():
    """Test upload session metadata handling"""
    print("Testing upload session metadata...")
    
    # Create a mock session with merge metadata
    session = UploadSession(
        session_id="test-session-id",
        user_id="test-user",
        filename="test-video.mp4",
        file_size=5000000,
        chunk_size=1048576,
        total_chunks=5,
        mime_type="video/mp4",
        metadata={
            "merge_session_id": "test-merge-session",
            "video_index": 0,
            "video_count": 3,
            "is_merge_video": True,
            "challenge_title": "Test Challenge",
            "total_duration": 45.7,
            "video_duration": 15.0
        }
    )
    
    # Validate metadata structure
    metadata = session.metadata
    
    required_fields = [
        "merge_session_id", "video_index", "video_count", 
        "is_merge_video", "total_duration", "video_duration"
    ]
    
    for field in required_fields:
        if field not in metadata:
            print(f"‚úó Missing required metadata field: {field}")
            return False
    
    # Validate metadata values
    if not isinstance(metadata["video_index"], int) or metadata["video_index"] < 0:
        print("‚úó Invalid video_index in metadata")
        return False
    
    if metadata["video_count"] != 3:
        print("‚úó Invalid video_count in metadata")
        return False
    
    if not metadata["is_merge_video"]:
        print("‚úó is_merge_video should be True")
        return False
    
    if metadata["video_duration"] <= 0:
        print("‚úó Invalid video_duration in metadata")
        return False
    
    print("‚úì All metadata validation checks passed")
    return True

async def test_merge_session_status_logic():
    """Test merge session status calculation logic"""
    print("Testing merge session status logic...")
    
    # Mock sessions for a merge session
    sessions = {
        "session1": UploadSession(
            session_id="session1",
            user_id="test-user",
            filename="video1.mp4",
            file_size=5000000,
            chunk_size=1048576,
            total_chunks=5,
            mime_type="video/mp4",
            status=UploadStatus.COMPLETED,
            metadata={"merge_session_id": "test-merge", "video_index": 0, "is_merge_video": True}
        ),
        "session2": UploadSession(
            session_id="session2",
            user_id="test-user",
            filename="video2.mp4",
            file_size=4500000,
            chunk_size=1048576,
            total_chunks=5,
            mime_type="video/mp4",
            status=UploadStatus.IN_PROGRESS,
            metadata={"merge_session_id": "test-merge", "video_index": 1, "is_merge_video": True}
        ),
        "session3": UploadSession(
            session_id="session3",
            user_id="test-user",
            filename="video3.mp4",
            file_size=5500000,
            chunk_size=1048576,
            total_chunks=5,
            mime_type="video/mp4",
            status=UploadStatus.PENDING,
            metadata={"merge_session_id": "test-merge", "video_index": 2, "is_merge_video": True}
        )
    }
    
    # Find sessions for merge session
    merge_sessions = []
    for session_id, session in sessions.items():
        if session.metadata.get("merge_session_id") == "test-merge":
            merge_sessions.append({
                "session_id": session_id,
                "video_index": session.metadata.get("video_index"),
                "status": session.status,
                "progress_percent": 80.0 if session.status == UploadStatus.IN_PROGRESS else 
                                  (100.0 if session.status == UploadStatus.COMPLETED else 0.0)
            })
    
    # Sort by video index
    merge_sessions.sort(key=lambda x: x.get("video_index", 0))
    
    # Calculate status
    total_videos = len(merge_sessions)
    completed_videos = sum(1 for s in merge_sessions if s["status"] == UploadStatus.COMPLETED)
    failed_videos = sum(1 for s in merge_sessions if s["status"] == UploadStatus.FAILED)
    
    if completed_videos == total_videos:
        overall_status = "ready_for_merge"
    elif failed_videos > 0:
        overall_status = "failed"
    elif completed_videos > 0:
        overall_status = "partially_uploaded"
    else:
        overall_status = "uploading"
    
    # Calculate progress
    total_progress = sum(s["progress_percent"] for s in merge_sessions)
    overall_progress = total_progress / total_videos if total_videos > 0 else 0.0
    
    # Validate results
    if total_videos != 3:
        print(f"‚úó Expected 3 videos, got {total_videos}")
        return False
    
    if completed_videos != 1:
        print(f"‚úó Expected 1 completed video, got {completed_videos}")
        return False
    
    if overall_status != "partially_uploaded":
        print(f"‚úó Expected 'partially_uploaded' status, got '{overall_status}'")
        return False
    
    expected_progress = (100.0 + 80.0 + 0.0) / 3  # ~60%
    if abs(overall_progress - expected_progress) > 0.1:
        print(f"‚úó Expected progress ~{expected_progress:.1f}%, got {overall_progress:.1f}%")
        return False
    
    print(f"‚úì Status calculation: {overall_status}")
    print(f"‚úì Progress calculation: {overall_progress:.1f}%")
    print(f"‚úì Videos: {completed_videos}/{total_videos} completed")
    
    return True

async def test_error_handling():
    """Test error handling scenarios"""
    print("Testing error handling...")
    
    # Test invalid video count
    try:
        video_count = 2  # Should be 3
        if video_count != 3:
            # This should raise an error in the actual endpoint
            print("‚úì Video count validation working")
    except Exception as e:
        print(f"‚úó Unexpected error in video count validation: {e}")
        return False
    
    # Test mismatched array lengths
    try:
        filenames = ["video1.mp4", "video2.mp4"]  # 2 items
        file_sizes = [1000000, 2000000, 3000000]  # 3 items
        
        if len(filenames) != len(file_sizes):
            # This should raise an error in the actual endpoint
            print("‚úì Array length validation working")
    except Exception as e:
        print(f"‚úó Unexpected error in array length validation: {e}")
        return False
    
    # Test invalid JSON
    try:
        invalid_json = "{'invalid': json}"  # Invalid JSON syntax
        json.loads(invalid_json)
        print("‚úó JSON validation should have failed")
        return False
    except json.JSONDecodeError:
        print("‚úì JSON validation working")
    
    return True

async def main():
    """Run all integration tests"""
    print("=" * 60)
    print("Challenge Video Endpoints Integration Test Suite")
    print("=" * 60)
    
    tests = [
        test_initiate_multi_video_upload_logic,
        test_upload_session_metadata,
        test_merge_session_status_logic,
        test_error_handling
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if await test():
                passed += 1
                print(f"‚úì {test.__name__} PASSED")
            else:
                print(f"‚úó {test.__name__} FAILED")
        except Exception as e:
            print(f"‚úó {test.__name__} ERROR: {e}")
            import traceback
            traceback.print_exc()
        print("-" * 40)
    
    print(f"\nIntegration Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ All integration tests passed!")
        return 0
    else:
        print("‚ùå Some integration tests failed")
        return 1

if __name__ == "__main__":
    sys.exit(asyncio.run(main()))